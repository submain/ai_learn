{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9d226d2-bf65-46c4-ae95-2f1a90446ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import d2l.torch as d2l\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "db62ca09-a6bc-4a72-afa6-312e7c8ecea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    with open('./The Echo of a Dying Star.txt','r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+',' ',line).strip().lower() for line in lines]\n",
    "\n",
    "    \n",
    "def tokenize(lines,token='word'):\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token=='char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误，未知词元类型:'+token)\n",
    "\n",
    "#统计词元频率\n",
    "def count_conpus(tokens):\n",
    "    if len(tokens) == 0 or isinstance(tokens[0],list):\n",
    "        #把词元列表展平成使用词元填充的一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "01a898fd-7d12-4894-915f-e476ee841293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合所有的功能\n",
    "def load_corpus_file(max_tokens=-1):\n",
    "    \"\"\"返回时光机器文本数据集中的词元索引和词汇表\"\"\"\n",
    "    lines = read_file()\n",
    "    tokens = tokenize(lines,'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    #把所有文本行展平到一个列表\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9417e686-8398-4736-9c9e-25ce17897bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#词汇表类\n",
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_token=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_token is None:\n",
    "            reserved_token = []\n",
    "        #按照出现的频率进行排序\n",
    "        counter = count_conpus(tokens)\n",
    "        self.token_freqs = sorted(counter.items(),key=lambda x: x[1],reverse=True)\n",
    "        #未知的词元索引为0\n",
    "        self.unk,uniq_tokens = 0,['<unk>'] + reserved_token\n",
    "        uniq_tokens += [token for token,freq in self.token_freqs if freq >= min_freq and tokens not in uniq_tokens]\n",
    "        self.idx_to_token,self.token_to_idx = [],dict()\n",
    "        for token in uniq_tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token]=len(self.idx_to_token) - 1\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6dcfbf28-0593-4039-a0cd-50cb99abce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "#随机采样\n",
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    #考虑标签，所以-1\n",
    "    num_subseqs = (len(corpus) -1) // num_steps\n",
    "    #序列的起始索引\n",
    "    initial_indices = list(range(random.randint(0,5),num_subseqs * num_steps,num_steps))\n",
    "    print(initial_indices)\n",
    "    #为了随机的效果，打乱initial_indices\n",
    "    random.shuffle(initial_indices)\n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0,batch_size * num_batches,batch_size):\n",
    "        initial_indices_per_batch = initial_indices[i:i+batch_size]\n",
    "        #取数据\n",
    "        x = [data(j) for j in initial_indices_per_batch]\n",
    "        y = [data(j+1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(x),torch.tensor(y)\n",
    "\n",
    "#顺序采样\n",
    "def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "    #有效tokens长度\n",
    "    index = random.randint(0,num_steps)\n",
    "    num_tokens = ((len(corpus) - index -1) // batch_size) * batch_size\n",
    "    xs = torch.tensor(corpus[index:index + num_tokens])\n",
    "    ys = torch.tensor(corpus[index + 1:index + num_tokens + 1])\n",
    "    #print(xs,ys)\n",
    "    xs,ys = xs.reshape(batch_size,-1),ys.reshape(batch_size,-1)\n",
    "    \n",
    "    num_batches = xs.shape[1] // num_steps\n",
    "    for i in range(0,num_steps * num_batches,num_steps):\n",
    "        x = xs[:,i:i+num_steps]\n",
    "        y = ys[:,i:i+num_steps]\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a41f39be-c569-4018-930c-8b28088b8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#把两个采样函数包装到类中，方便后续使用\n",
    "class SeqDataLoader:\n",
    "    def __init__(self,batch_size,num_steps,use_random_iter,max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        self.corpus,self.vocab = load_corpus_file(max_tokens)\n",
    "        self.batch_size,self.num_steps = batch_size,num_steps\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus,self.batch_size,self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1f79bcab-3b9e-4d8b-8c74-c4d113ab2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file(batch_size,num_steps,use_random_iter=False,max_tokens=10000):\n",
    "    data_iter = SeqDataLoader(batch_size,num_steps,use_random_iter,max_tokens)\n",
    "    return data_iter,data_iter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "853a805f-f4f9-4aec-aeff-3ccdaca2a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 加载file数据\n",
    "batch_size,num_steps = 32,35\n",
    "train_iter,vocab = load_data_file(batch_size=batch_size,num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9dcc1225-77d0-4a38-b2d7-2b95eb892bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#包装成类\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # RNN层 (可以选择 LSTM 或 GRU)\n",
    "        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 输出层\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, state=None):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # 嵌入层\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embed_size)\n",
    "        \n",
    "        # RNN前向传播\n",
    "        if state is None:\n",
    "            # 初始化隐藏状态\n",
    "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "            state = (h0, c0)\n",
    "        \n",
    "        output, state = self.rnn(embedded, state)  # output: (batch_size, seq_len, hidden_size)\n",
    "        display(output.shape,state.shape)\n",
    "        \n",
    "        # 全连接层\n",
    "        output = self.fc(output)  # (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        # 重塑输出以便计算损失\n",
    "        output = output.reshape(-1, output.shape[2])  # (batch_size * seq_len, vocab_size)\n",
    "        \n",
    "        return output, state\n",
    "    \n",
    "    def begin_state(self, batch_size, device):\n",
    "        # 初始化隐藏状态\n",
    "        return (\n",
    "            torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e7b1cbd-35ef-41cb-bb97-a512a2cb65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "243610b9-91aa-49ca-9a76-cb5f5408f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, vocab_size, num_epochs, lr, device):\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 将模型移到设备\n",
    "    model.to(device)\n",
    "    \n",
    "    # 记录训练历史\n",
    "    history = {'loss': [], 'perplexity': [], 'time': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 设置训练模式\n",
    "        total_loss = 0\n",
    "        total_tokens = 0\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        for batch_idx, (X, Y) in enumerate(train_loader):\n",
    "            # 移动到设备\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs, _ = model(X)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, Y.view(-1))\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # 梯度裁剪（防止梯度爆炸）\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 记录统计信息\n",
    "            total_loss += loss.item() * Y.numel()\n",
    "            total_tokens += Y.numel()\n",
    "        \n",
    "        # 计算epoch指标\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        avg_loss = total_loss / total_tokens\n",
    "        #display(avg_loss)\n",
    "        perplexity = math.exp(avg_loss)\n",
    "        tokens_per_sec = total_tokens / epoch_time\n",
    "        \n",
    "        # 记录历史\n",
    "        history['loss'].append(avg_loss)\n",
    "        history['perplexity'].append(perplexity)\n",
    "        history['time'].append(epoch_time)\n",
    "        \n",
    "        # 打印进度\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] | '\n",
    "                  f'Loss: {avg_loss:.4f} | '\n",
    "                  f'Perplexity: {perplexity:.2f} | '\n",
    "                  f'Speed: {tokens_per_sec:.1f} tokens/sec')\n",
    "    \n",
    "    return history\n",
    "\n",
    "# 辅助函数：分离隐藏状态\n",
    "def detach_state(state):\n",
    "    if isinstance(state, tuple):\n",
    "        return (state[0].detach(), state[1].detach())\n",
    "    else:\n",
    "        return state.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "194cfe56-ccaf-4ede-8d36-675eb75934ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "模型参数量: 932,380\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'使用设备: {device}')\n",
    "\n",
    "# 准备数据\n",
    "train_loader, vocab_size = train_iter,len(vocab)\n",
    "# 模型参数\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "# 创建模型\n",
    "model = RNNModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "print(f'模型参数量: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "712f444d-ce45-448c-9946-c6be99bacb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "Epoch [1/1] | Loss: 2.8540 | Perplexity: 17.36 | Speed: 24419.2 tokens/sec\n",
      "训练完成!\n",
      "最终困惑度: 17.36\n"
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "num_epochs = 1\n",
    "learning_rate = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "# 开始训练\n",
    "print('开始训练...')\n",
    "history = train_model(model, train_loader, vocab_size, num_epochs, learning_rate, device)\n",
    "\n",
    "print('训练完成!')\n",
    "print(f'最终困惑度: {history[\"perplexity\"][-1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4594e0-4e8b-46aa-ad37-8ee6cf08444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "def predict(prefix,num_preds,net,vocab,device):\n",
    "    state = net.begin_state(batch_size=1,device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "\n",
    "    get_input = lambda : torch.tensor([outputs[-1]],device=device).reshape((1,1))\n",
    "    #预热\n",
    "    for u in prefix[1:]:\n",
    "        #print(get_input())\n",
    "        _,state = net(get_input(),state)\n",
    "        outputs.append(vocab[u])\n",
    "    #真正预测\n",
    "    for _ in range(num_preds):\n",
    "        y,state = net(get_input(),state)\n",
    "        #print('真正预测:',y)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3f3786a7-782a-471a-8069-1bc61eaab0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>t wasn<unk>t a sound the the the the the the the the the the the the t'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lambda prefix:predict(prefix,50,model,vocab,device)\n",
    "pred(\"It wasn't a sound\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d6362-6510-42cf-ad8a-963b546d8e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d27e3-00e2-4b0e-8a05-d490707eee2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5a29a-0752-4b06-bc1b-c1b476695bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a606b09-c454-47d7-bf36-e391fe416dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb85dfd-821b-4066-a1be-fec2d532fac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d4da7-b722-4d36-abe4-b81b751f6a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f0902-a0c6-42bc-a205-990a65702050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffb3d0-0f29-4840-9468-6f28aee6b160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfdfdd-c948-4bec-8e7f-f93667002cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25605cb8-e6e3-4f21-864c-dcfa29c2e41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c79090-5cf3-4aae-9520-4f22c3c424c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fca737-ef5a-43e2-9ba1-e9e97f0b3d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e05f9-da23-4a84-990e-945070a26150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe3ef1-6592-4e73-8cc4-283d3b969400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c7e21-71e7-464b-a82f-56c490fc9020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
