{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b13405-04ba-465a-bab5-6de935a62eee",
   "metadata": {},
   "source": [
    "### 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8522c6ea-9f11-496a-8050-c132db2a572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文本作为字符串加载到内存\n",
    "# 将字符串拆分为词元（如单词和字符）\n",
    "# 建立一个词汇表，将拆分的词元映射到数字索引\n",
    "# 将文本转换为数字索引序列，方便模型操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6953762b-3b5f-449c-9b81-5770782a64f6",
   "metadata": {},
   "source": [
    "#### 1、读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bf055b5-4710-4ba5-ad5f-4d8ad7e279d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "923d0b5e-e2fc-4170-9988-d062ee189f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_time_mechaine():\n",
    "    with open('./The Echo of a Dying Star.txt','r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+',' ',line).strip().lower() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76d4e46e-f5b0-4484-b26a-ebf017255042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# text lines:71\n",
      "title the echo of a dying star\n",
      "initiate the sequence aris s voice was calm belying the tremor in her hands on the viewscreen the asteroid hangar bay doors retracted revealing the inky blackness dotted with pinpricks of light\n"
     ]
    }
   ],
   "source": [
    "lines = read_time_mechaine()\n",
    "print(f'# text lines:{len(lines)}' )\n",
    "print(lines[0])\n",
    "print(lines[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045a9a5-a8a5-46cb-8b28-4f1789212a64",
   "metadata": {},
   "source": [
    "#### 2、词元化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d7e25f7-ab65-4ce6-a62e-25bc6e6d88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lines,token='word'):\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token=='char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误，未知词元类型:'+token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7732fe1-3654-43ee-9928-16ae432e6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'i', 't', 'l', 'e', ' ', 't', 'h', 'e', ' ', 'e', 'c', 'h', 'o', ' ', 'o', 'f', ' ', 'a', ' ', 'd', 'y', 'i', 'n', 'g', ' ', 's', 't', 'a', 'r']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize(lines,token='char')\n",
    "for i in range(2):\n",
    "    print(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cc2a3-57e1-4d5d-83c6-690088ddb557",
   "metadata": {},
   "source": [
    "#### 3、构建词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8394b2cd-4ccb-4839-a04e-7e2a0fb74eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计词元频率\n",
    "def count_conpus(tokens):\n",
    "    if len(tokens) == 0 or isinstance(tokens[0],list):\n",
    "        #把词元列表展平成使用词元填充的一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8642fd7a-0ae8-40ac-b15e-4ec985a3e127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_conpus(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9213fda7-96fc-4864-9059-93a7a34bd3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 1063),\n",
       " ('e', 677),\n",
       " ('t', 499),\n",
       " ('a', 435),\n",
       " ('i', 386),\n",
       " ('n', 344),\n",
       " ('s', 342),\n",
       " ('r', 330),\n",
       " ('o', 304),\n",
       " ('h', 253),\n",
       " ('l', 213),\n",
       " ('d', 186),\n",
       " ('c', 163),\n",
       " ('u', 119),\n",
       " ('g', 117),\n",
       " ('w', 109),\n",
       " ('f', 105),\n",
       " ('p', 102),\n",
       " ('m', 92),\n",
       " ('y', 87),\n",
       " ('b', 63),\n",
       " ('v', 56),\n",
       " ('k', 46),\n",
       " ('q', 6),\n",
       " ('x', 5),\n",
       " ('j', 5),\n",
       " ('z', 2)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python自带排序方法\n",
    "sorted(count_conpus(tokens).items(),key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "425c7e92-ce4c-48af-bb47-1d6ba8cee198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#词汇表类\n",
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_token=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_token is None:\n",
    "            reserved_token = []\n",
    "        #按照出现的频率进行排序\n",
    "        counter = count_conpus(tokens)\n",
    "        self.token_freqs = sorted(counter.items(),key=lambda x: x[1],reverse=True)\n",
    "        #未知的词元索引为0\n",
    "        self.unk,uniq_tokens = 0,['<unk>'] + reserved_token\n",
    "        uniq_tokens += [token for token,freq in self.token_freqs if freq >= min_freq and tokens not in uniq_tokens]\n",
    "        self.idx_to_token,self.token_to_idx = [],dict()\n",
    "        for token in uniq_tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token]=len(self.idx_to_token) - 1\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85fb4ac9-c236-4765-999a-db3447d41681",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54660df8-6cb1-43cc-9900-6d8b4312d052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4fe9fbe6-409b-4777-a8cb-e796428c4e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " ' ': 1,\n",
       " 'e': 2,\n",
       " 't': 3,\n",
       " 'a': 4,\n",
       " 'i': 5,\n",
       " 'n': 6,\n",
       " 's': 7,\n",
       " 'r': 8,\n",
       " 'o': 9,\n",
       " 'h': 10,\n",
       " 'l': 11,\n",
       " 'd': 12,\n",
       " 'c': 13,\n",
       " 'u': 14,\n",
       " 'g': 15,\n",
       " 'w': 16,\n",
       " 'f': 17,\n",
       " 'p': 18,\n",
       " 'm': 19,\n",
       " 'y': 20,\n",
       " 'b': 21,\n",
       " 'v': 22,\n",
       " 'k': 23,\n",
       " 'q': 24,\n",
       " 'x': 25,\n",
       " 'j': 26,\n",
       " 'z': 27}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ff4e1c1-1faa-41f1-9acb-d7e81335556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['t', 'i', 't', 'l', 'e', ' ', 't', 'h', 'e', ' ', 'e', 'c', 'h', 'o', ' ', 'o', 'f', ' ', 'a', ' ', 'd', 'y', 'i', 'n', 'g', ' ', 's', 't', 'a', 'r']\n",
      "indices: [3, 5, 3, 11, 2, 1, 3, 10, 2, 1, 2, 13, 10, 9, 1, 9, 17, 1, 4, 1, 12, 20, 5, 6, 15, 1, 7, 3, 4, 8]\n",
      "words: ['i', 'n', 'i', 't', 'i', 'a', 't', 'e', ' ', 't', 'h', 'e', ' ', 's', 'e', 'q', 'u', 'e', 'n', 'c', 'e', ' ', 'a', 'r', 'i', 's', ' ', 's', ' ', 'v', 'o', 'i', 'c', 'e', ' ', 'w', 'a', 's', ' ', 'c', 'a', 'l', 'm', ' ', 'b', 'e', 'l', 'y', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 't', 'r', 'e', 'm', 'o', 'r', ' ', 'i', 'n', ' ', 'h', 'e', 'r', ' ', 'h', 'a', 'n', 'd', 's', ' ', 'o', 'n', ' ', 't', 'h', 'e', ' ', 'v', 'i', 'e', 'w', 's', 'c', 'r', 'e', 'e', 'n', ' ', 't', 'h', 'e', ' ', 'a', 's', 't', 'e', 'r', 'o', 'i', 'd', ' ', 'h', 'a', 'n', 'g', 'a', 'r', ' ', 'b', 'a', 'y', ' ', 'd', 'o', 'o', 'r', 's', ' ', 'r', 'e', 't', 'r', 'a', 'c', 't', 'e', 'd', ' ', 'r', 'e', 'v', 'e', 'a', 'l', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'i', 'n', 'k', 'y', ' ', 'b', 'l', 'a', 'c', 'k', 'n', 'e', 's', 's', ' ', 'd', 'o', 't', 't', 'e', 'd', ' ', 'w', 'i', 't', 'h', ' ', 'p', 'i', 'n', 'p', 'r', 'i', 'c', 'k', 's', ' ', 'o', 'f', ' ', 'l', 'i', 'g', 'h', 't']\n",
      "indices: [5, 6, 5, 3, 5, 4, 3, 2, 1, 3, 10, 2, 1, 7, 2, 24, 14, 2, 6, 13, 2, 1, 4, 8, 5, 7, 1, 7, 1, 22, 9, 5, 13, 2, 1, 16, 4, 7, 1, 13, 4, 11, 19, 1, 21, 2, 11, 20, 5, 6, 15, 1, 3, 10, 2, 1, 3, 8, 2, 19, 9, 8, 1, 5, 6, 1, 10, 2, 8, 1, 10, 4, 6, 12, 7, 1, 9, 6, 1, 3, 10, 2, 1, 22, 5, 2, 16, 7, 13, 8, 2, 2, 6, 1, 3, 10, 2, 1, 4, 7, 3, 2, 8, 9, 5, 12, 1, 10, 4, 6, 15, 4, 8, 1, 21, 4, 20, 1, 12, 9, 9, 8, 7, 1, 8, 2, 3, 8, 4, 13, 3, 2, 12, 1, 8, 2, 22, 2, 4, 11, 5, 6, 15, 1, 3, 10, 2, 1, 5, 6, 23, 20, 1, 21, 11, 4, 13, 23, 6, 2, 7, 7, 1, 12, 9, 3, 3, 2, 12, 1, 16, 5, 3, 10, 1, 18, 5, 6, 18, 8, 5, 13, 23, 7, 1, 9, 17, 1, 11, 5, 15, 10, 3]\n"
     ]
    }
   ],
   "source": [
    "for i in [0,10]:\n",
    "    print('words:',tokens[i])\n",
    "    print('indices:',vocab[tokens[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf2f54c5-a016-4e0f-ba41-8efae41fd4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合所有的功能\n",
    "def load_corpus_time_machine(max_tokens=-1):\n",
    "    \"\"\"返回时光机器文本数据集中的词元索引和词汇表\"\"\"\n",
    "    lines = read_time_mechaine()\n",
    "    tokens = tokenize(lines,'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    #把所有文本行展平到一个列表\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1c227a0-cc54-4e0f-befc-1f25be6e4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus,vocab = load_corpus_time_machine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33024e44-5632-41f6-8cba-3be310cc42ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6109"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cbb0e52-594c-414a-9849-4b0e8c128eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21e897-6696-4baf-b375-2eb580457a29",
   "metadata": {},
   "source": [
    "#### 4、序列数据采样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94ef1a2e-1e20-460d-b2f7-16685739cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e68cede-31b5-439d-b383-63225eb38152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机采样\n",
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    #考虑标签，所以-1\n",
    "    num_subseqs = (len(corpus) -1) // num_steps\n",
    "    #序列的起始索引\n",
    "    initial_indices = list(range(random.randint(0,5),num_subseqs * num_steps,num_steps))\n",
    "    print(initial_indices)\n",
    "    #为了随机的效果，打乱initial_indices\n",
    "    random.shuffle(initial_indices)\n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0,batch_size * num_batches,batch_size):\n",
    "        initial_indices_per_batch = initial_indices[i:i+batch_size]\n",
    "        #取数据\n",
    "        x = [data(j) for j in initial_indices_per_batch]\n",
    "        y = [data(j+1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(x),torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "327adaef-b2b1-45f4-85f8-c5315fd57258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 11, 16, 21, 26]\n",
      "x: tensor([[21, 22, 23, 24, 25],\n",
      "        [ 1,  2,  3,  4,  5]]) \n",
      "y: tensor([[22, 23, 24, 25, 26],\n",
      "        [ 2,  3,  4,  5,  6]])\n",
      "x: tensor([[11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20]]) \n",
      "y: tensor([[12, 13, 14, 15, 16],\n",
      "        [17, 18, 19, 20, 21]])\n",
      "x: tensor([[ 6,  7,  8,  9, 10],\n",
      "        [26, 27, 28, 29, 30]]) \n",
      "y: tensor([[ 7,  8,  9, 10, 11],\n",
      "        [27, 28, 29, 30, 31]])\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for x,y in seq_data_iter_random(my_seq,batch_size=2,num_steps=5):\n",
    "    print('x:',x,'\\ny:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ef51a5e6-ad3a-4313-9cba-9177b9c8b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#顺序采样\n",
    "def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "    #有效tokens长度\n",
    "    index = random.randint(0,num_steps)\n",
    "    num_tokens = ((len(corpus) - index -1) // batch_size) * batch_size\n",
    "    xs = torch.tensor(corpus[index:index + num_tokens])\n",
    "    ys = torch.tensor(corpus[index + 1:index + num_tokens + 1])\n",
    "    #print(xs,ys)\n",
    "    xs,ys = xs.reshape(batch_size,-1),ys.reshape(batch_size,-1)\n",
    "    \n",
    "    num_batches = xs.shape[1] // num_steps\n",
    "    for i in range(0,num_steps * num_batches,num_steps):\n",
    "        x = xs[:,i:i+num_steps]\n",
    "        y = ys[:,i:i+num_steps]\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8533d950-581c-45fa-891b-1cd9b9740a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b7381782-2bde-4007-b9b0-a0c38c15dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 5,  6,  7,  8,  9],\n",
      "        [19, 20, 21, 22, 23]]) \n",
      "y: tensor([[ 6,  7,  8,  9, 10],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "x: tensor([[10, 11, 12, 13, 14],\n",
      "        [24, 25, 26, 27, 28]]) \n",
      "y: tensor([[11, 12, 13, 14, 15],\n",
      "        [25, 26, 27, 28, 29]])\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for x,y in seq_data_iter_sequential(my_seq,batch_size=2,num_steps=5):\n",
    "    print('x:',x,'\\ny:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bcc29339-146c-4646-a064-31f8078d12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#把两个采样函数包装到类中，方便后续使用\n",
    "class SeqDataLoader:\n",
    "    def __init__(self,batch_size,num_steps,use_random_iter,max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        self.corpus,self.vocab = load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size,self.num_steps = batch_size,num_steps\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus,self.batch_size,self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2864b305-ef49-4da6-aaeb-3c91b5334130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_time_matchine(batch_size,num_steps,use_random_iter=False,max_tokens=10000):\n",
    "    data_iter = SeqDataLoader(batch_size,num_steps,use_random_iter,max_tokens)\n",
    "    return data_iter,data_iter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6f70b004-cf63-46f8-b7ae-bc332e9cfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size,num_steps = 2,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f84626c1-0162-4a50-8426-fc1618d4c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader,vocab = load_data_time_matchine(batch_size,num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "90971248-70d5-482a-acb8-fbde915f5a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 2, 13, 10,  9,  1,  9, 17,  1,  4,  1],\n",
      "        [ 5,  6,  2,  1,  4,  6, 12,  1, 16,  2]]), tensor([[13, 10,  9,  1,  9, 17,  1,  4,  1, 12],\n",
      "        [ 6,  2,  1,  4,  6, 12,  1, 16,  2,  1]]))\n"
     ]
    }
   ],
   "source": [
    "for i in loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca47867-3f10-4b16-bd7a-6bcb723a5768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e690c-6d14-42fb-9abe-22ce3f7856cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100bff0a-5b8a-499d-b227-7870703c096c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07f81d-b3db-404c-9d78-2f6130141ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cfd8c-c05f-424b-bc72-c287929dfd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbd2f1-a5f3-4090-be8f-c0df3a6cb8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3f8a0-99e0-4a89-888a-1bd5fb0eec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522243b5-e05f-4ec4-b425-29b717521beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1dfc7d-b431-4f35-9e15-3ec6d33348bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
